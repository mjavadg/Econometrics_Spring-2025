{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06afd08e-c8fd-4ba8-bfdf-b66016efa2d3",
   "metadata": {},
   "source": [
    "# Econometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32391cf7-9617-400c-9b20-491dde5fd6d9",
   "metadata": {},
   "source": [
    "# 8th Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e022f17-edee-4f4d-9cbb-f0193dbafafb",
   "metadata": {},
   "source": [
    "# Simulating Instrumental Variable Data and Performing 2SLS Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa9df96-724a-4103-b2b8-84088f14d226",
   "metadata": {},
   "source": [
    "# The goal of econometrics is to understand the relationships between variables accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58299f98-b092-4bdf-aefc-133542fbfab8",
   "metadata": {},
   "source": [
    "### Importing data from the excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b48fdd-1d6d-4e94-b5ad-2e13006b2a3c",
   "metadata": {},
   "source": [
    "### Using the simulation in the appendix, I created this Excel file. I generated Y values using an intercept of 0.7 and an X variable with a coefficient of 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8e7de6c-fc3f-404e-8c42-1e06a4171122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fe22dba7-93af-4035-946d-408835da953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"IV_data_session_8_example.xlsx\")\n",
    "\n",
    "Y = data[\"Y\"]\n",
    "X = data[\"X\"]\n",
    "Z = data[\"Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9a6a0-a1a5-4036-8009-5b936005a990",
   "metadata": {},
   "source": [
    "### Checking the correlation between Z and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "adcbf49b-0b81-46cd-8c62-e277aee13689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.67194391],\n",
       "       [0.67194391, 1.        ]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(Z, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f32a6-8166-411b-a664-5ccd721bad2d",
   "metadata": {},
   "source": [
    "### Checking the covariance between X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "da1988af-7ee7-4ec1-80a7-52ad86b9d76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   65.44454431,   220.50413431],\n",
       "       [  220.50413431, 18969.22434043]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f97887-886d-4b71-824e-6554ef42c13e",
   "metadata": {},
   "source": [
    "### Checking the covariance between Z and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cc9dee54-a4c6-41fb-bd38-ae14023ea9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60768174e+01, 2.61547776e+01],\n",
       "       [2.61547776e+01, 1.89692243e+04]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(Z, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f73b28-3d4f-4c75-9e37-2bcb7c9fe712",
   "metadata": {},
   "source": [
    "### Impelmenting OLS Y and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b764219f-7593-4054-bffc-3e4bcc86a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS result: \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.039\n",
      "Method:                 Least Squares   F-statistic:                     407.5\n",
      "Date:                Fri, 06 Jun 2025   Prob (F-statistic):           7.30e-89\n",
      "Time:                        00:57:39   Log-Likelihood:                -63242.\n",
      "No. Observations:               10000   AIC:                         1.265e+05\n",
      "Df Residuals:                    9998   BIC:                         1.265e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -28.5733      2.626    -10.882      0.000     -33.721     -23.426\n",
      "X              3.3693      0.167     20.188      0.000       3.042       3.696\n",
      "==============================================================================\n",
      "Omnibus:                     2691.440   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9423.961\n",
      "Skew:                           1.332   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.939   Cond. No.                         30.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_ols = sm.add_constant(X)\n",
    "ols_model = sm.OLS(Y, X_ols).fit()\n",
    "\n",
    "print(\"OLS result: \")\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b902568-edc5-4678-9c28-8399be4bd82c",
   "metadata": {},
   "source": [
    "### The estimated coefficient is 3.36 instead of the expected 1.2, indicating that something is not right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648648ce-837d-4759-a325-eff3d9a43319",
   "metadata": {},
   "source": [
    "### Using the instrumental variable Z, I estimated the endogenous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "531aa5a0-4912-421a-a0a7-94ffba300a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First OLS result: \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      X   R-squared:                       0.452\n",
      "Model:                            OLS   Adj. R-squared:                  0.451\n",
      "Method:                 Least Squares   F-statistic:                     8230.\n",
      "Date:                Fri, 06 Jun 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:02:32   Log-Likelihood:                -32092.\n",
      "No. Observations:               10000   AIC:                         6.419e+04\n",
      "Df Residuals:                    9998   BIC:                         6.420e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0691      0.161     -0.429      0.668      -0.385       0.247\n",
      "Z              1.3557      0.015     90.720      0.000       1.326       1.385\n",
      "==============================================================================\n",
      "Omnibus:                        2.236   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.327   Jarque-Bera (JB):                2.277\n",
      "Skew:                           0.005   Prob(JB):                        0.320\n",
      "Kurtosis:                       3.073   Cond. No.                         29.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Z_intercept = sm.add_constant(Z)\n",
    "first_stage_model = sm.OLS(X, Z_intercept).fit()\n",
    "X_hat = first_stage_model.fittedvalues\n",
    "\n",
    "print(\"First OLS result: \")\n",
    "print(first_stage_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b15f7-f341-4cd9-a077-2abac5fd980b",
   "metadata": {},
   "source": [
    "### Then, I used the estimated values of X to run a regression with Y as the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "08742f91-aa18-41d5-a253-2363807a5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second OLS result: \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     22.48\n",
      "Date:                Fri, 06 Jun 2025   Prob (F-statistic):           2.16e-06\n",
      "Time:                        01:05:01   Log-Likelihood:                -63431.\n",
      "No. Observations:               10000   AIC:                         1.269e+05\n",
      "Df Residuals:                    9998   BIC:                         1.269e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7000      3.682      0.190      0.849      -6.518       7.918\n",
      "0              1.2000      0.253      4.741      0.000       0.704       1.696\n",
      "==============================================================================\n",
      "Omnibus:                     3051.222   Durbin-Watson:                   2.033\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11174.468\n",
      "Skew:                           1.503   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.218   Cond. No.                         39.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_hat_intercept = sm.add_constant(X_hat)\n",
    "second_stage_model = sm.OLS(Y, X_hat_intercept).fit()\n",
    "\n",
    "print(\"Second OLS result: \")\n",
    "print(second_stage_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209bf3b4-0fef-4d46-9ee1-2b2295fe5b51",
   "metadata": {},
   "source": [
    "### The estimated parameters are now 1.2 and 0.7, matching the values used in the data simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abc503",
   "metadata": {},
   "source": [
    "# Appendix 1:\n",
    "### Simulating Instrumental Variable Data with One Explanatory Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858dc02",
   "metadata": {},
   "source": [
    "**The process begins by generating the instrumental variable \\(Z\\) from a normal distribution, ensuring it has sufficient variation. Next, \\(X\\) is derived as a function of \\(Z\\) with added noise, reinforcing the correlation between them.**\n",
    "\n",
    "**To isolate the effect of \\(Z\\) on \\(X\\), a linear regression is performed, and the influence of \\(Z\\) is removed from \\(X\\) through the regression residuals. This step is crucial as it allows \\(X\\) to maintain some dependency on \\(Z\\) while controlling for its direct influence. Similarly, \\(\\epsilon\\) is constructed to have a non-zero covariance with \\(X\\) but a zero covariance with \\(Z\\), ensuring that \\(Z\\) does not directly affect the error term. This is achieved by orthogonalizing \\(\\epsilon\\) with respect to \\(Z\\), further isolating the relationships among the variables.**\n",
    "\n",
    "**Finally, \\(Y\\) is constructed as a linear function of \\(X\\) and \\(\\epsilon\\), incorporating predetermined coefficients to define the relationship. The resulting covariances and correlations are computed to analyze the dependencies among the variables, providing insights into their interactions and validating the assumptions underlying the model. This approach is fundamental in econometrics, particularly in scenarios involving instrumental variables and causal inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6def815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cov(X, Y): 234.3792105499043\n",
      "Cov(Z, Y): 26.35018334073745\n",
      "Cov(X, epsilon): 156.07069586581417\n",
      "Cov(Z, epsilon): 2.402215728955199e-13\n",
      "Correlation(Z, X): 0.6737881632562699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n = 10000\n",
    "alpha = 0.7\n",
    "beta = 1.2\n",
    "\n",
    "Z = np.random.normal(10, 4, n)  \n",
    "\n",
    "X_raw = 4.5 * Z + np.random.normal(0, 6, n)  \n",
    "\n",
    "#Removing Z‚Äôs effect from X using\n",
    "reg_X = LinearRegression().fit(Z.reshape(-1, 1), X_raw)\n",
    "lambda_factor = 0.3  #strength of correlation\n",
    "X = X_raw - (1 - lambda_factor) * reg_X.predict(Z.reshape(-1, 1))\n",
    "\n",
    "epsilon_raw = np.random.normal(0, 5, n) + np.random.gamma(2, 2, n) * X_raw\n",
    "\n",
    "# Remove Z‚Äôs effect from epsilon \n",
    "reg_epsilon = LinearRegression().fit(Z.reshape(-1, 1), epsilon_raw)\n",
    "epsilon = epsilon_raw - reg_epsilon.predict(Z.reshape(-1, 1))  #orthogonalizing Z out of epsilon\n",
    "\n",
    "Y = alpha + beta * X + epsilon\n",
    "\n",
    "cov_matrix = np.cov([X, Y, Z, epsilon])\n",
    "\n",
    "cov_X_Y = cov_matrix[0, 1]  #cov(X, Y)\n",
    "cov_Z_Y = cov_matrix[2, 1]  #cov(Z, Y)\n",
    "cov_X_epsilon = cov_matrix[0, 3]  #cov(X, epsilon)\n",
    "cov_Z_epsilon = cov_matrix[2, 3]  #cov(Z, epsilon)\n",
    "cor_Z_X = np.corrcoef(Z, X)[0, 1]  #correlation(Z, X)\n",
    "\n",
    "print(\"Cov(X, Y):\", cov_X_Y)\n",
    "print(\"Cov(Z, Y):\", cov_Z_Y)  \n",
    "print(\"Cov(X, epsilon):\", cov_X_epsilon)\n",
    "print(\"Cov(Z, epsilon):\", cov_Z_epsilon)  \n",
    "print(\"Correlation(Z, X):\", cor_Z_X)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980a67d",
   "metadata": {},
   "source": [
    "**We can force cov(ùëç, ùëå) to be zero by orthogonalizing ùëå with respect to ùëç, but this approach is not viable in IV estimation because it removes the variation necessary for the second-stage regression to identify an endogenous effect. A nonzero covariance between ùëç and ùëå (such as 26 in this result) is acceptable as long as ùëç does not directly affect the error term ùúñ. The simulation should focus on ensuring that ùëç is uncorrelated with ùúñ while remaining relevant for ùëã.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca026c",
   "metadata": {},
   "source": [
    "## Simulating Instrumental Variable Data with Two Explanatory Variables  \n",
    "*Note: Full code to be uploaded after the student assignment is complete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample size\n",
    "n = 10000\n",
    "alpha = 0.7\n",
    "beta1 = 1.2\n",
    "beta2 = -0.8\n",
    "\n",
    "# Generate instrumental variables Z1 and Z2\n",
    "Z1 = np.random.normal(10, 4, n)  # Unique variation\n",
    "Z2 = np.random.normal(5, 3, n)  # Different variation\n",
    "\n",
    "# Create endogenous variables X1 and X2 with dependence on Z1 and Z2\n",
    "X1_raw = 3.5 * Z1 + 2.0 * Z2 + np.random.normal(0, 5, n)\n",
    "X2_raw = 2.0 * Z1 + 4.0 * Z2 + np.random.normal(0, 5, n)\n",
    "\n",
    "# Remove Z‚Äôs effect using regression residuals to control correlation strength\n",
    "reg_X1 = LinearRegression().fit(np.column_stack((Z1, Z2)), X1_raw)\n",
    "lambda_factor1 = 0.3  # Adjust correlation strength\n",
    "X1 = X1_raw - (1 - lambda_factor1) * reg_X1.predict(np.column_stack((Z1, Z2)))\n",
    "\n",
    "reg_X2 = LinearRegression().fit(np.column_stack((Z1, Z2)), X2_raw)\n",
    "lambda_factor2 = 0.3  # Adjust correlation strength\n",
    "X2 = X2_raw - (1 - lambda_factor2) * reg_X2.predict(np.column_stack((Z1, Z2)))\n",
    "\n",
    "# Generate error term epsilon (ensuring Cov(X1, epsilon) ‚â† 0 and Cov(X2, epsilon) ‚â† 0)\n",
    "epsilon_raw = np.random.normal(0, 5, n) + np.random.gamma(2, 2, n) * (X1_raw + X2_raw)\n",
    "reg_epsilon = LinearRegression().fit(np.column_stack((Z1, Z2)), epsilon_raw)\n",
    "epsilon = epsilon_raw - reg_epsilon.predict(np.column_stack((Z1, Z2)))\n",
    "\n",
    "# Construct Y with correct coefficients\n",
    "Y = alpha + beta1 * X1 + beta2 * X2 + epsilon\n",
    "\n",
    "# Compute covariance and correlation matrices\n",
    "cov_matrix = np.cov([X1, X2, Y, Z1, Z2, epsilon])\n",
    "\n",
    "cov_X1_Y = cov_matrix[0, 2]  # cov(X1, Y)\n",
    "cov_X2_Y = cov_matrix[1, 2]  # cov(X2, Y)\n",
    "cov_Z1_Y = cov_matrix[3, 2]  # cov(Z1, Y)\n",
    "cov_Z2_Y = cov_matrix[4, 2]  # cov(Z2, Y)\n",
    "cov_X1_epsilon = cov_matrix[0, 5]  # cov(X1, epsilon)\n",
    "cov_X2_epsilon = cov_matrix[1, 5]  # cov(X2, epsilon)\n",
    "cov_Z1_epsilon = cov_matrix[3, 5]  # cov(Z1, epsilon)\n",
    "cov_Z2_epsilon = cov_matrix[4, 5]  # cov(Z2, epsilon)\n",
    "cor_Z1_X1 = np.corrcoef(Z1, X1)[0, 1]  # correlation(Z1, X1)\n",
    "cor_Z2_X2 = np.corrcoef(Z2, X2)[0, 1]  # correlation(Z2, X2)\n",
    "\n",
    "# Print results\n",
    "print(\"Cov(X1, Y):\", cov_X1_Y)\n",
    "print(\"Cov(X2, Y):\", cov_X2_Y)\n",
    "print(\"Cov(Z1, Y):\", cov_Z1_Y)  # Should be close to 0\n",
    "print(\"Cov(Z2, Y):\", cov_Z2_Y)  # Should be close to 0\n",
    "print(\"Cov(X1, epsilon):\", cov_X1_epsilon)\n",
    "print(\"Cov(X2, epsilon):\", cov_X2_epsilon)\n",
    "print(\"Cov(Z1, epsilon):\", cov_Z1_epsilon)  # Should be close to 0\n",
    "print(\"Cov(Z2, epsilon):\", cov_Z2_epsilon)  # Should be close to 0\n",
    "print(\"Correlation(Z1, X1):\", cor_Z1_X1)  # Should be **higher**\n",
    "print(\"Correlation(Z2, X2):\", cor_Z2_X2)  # Should be **higher**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32389748",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
